{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b01c06a"
      },
      "source": [
        "#Gated Graph Neural Networks for Event Causality Identification   from Social-Political News Articles"
      ],
      "id": "0b01c06a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a12e3e7e"
      },
      "source": [
        "### Abstract"
      ],
      "id": "a12e3e7e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "132dd151"
      },
      "source": [
        "The discovery of causality mentions from  text is a core cognitive concept and appears in many natural language processing (NLP) applications. In this paper, we study the task of Event Causality Identification  (ECI) from social-political news. The aim of the task is to detect causal relationships between event mention pairs in text.\n",
        "Although deep learning models have recently achieved a state-of-the-art performance on many  tasks and applications in NLP, most of them still fail to capture rich semantic and syntactic structures within sentences which is  key for causality classification.  \n",
        "We present a solution for causal event detection from social-political news that captures semantic and syntactic information based on gated graph neural networks (GGNN) and contextualized language embeddings. Experimental results show that our proposed method outperforms the baseline model (BERT (Bidirectional Embeddings from Transformers) in terms of f1-score and accuracy."
      ],
      "id": "132dd151"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for the paper\n",
        "## Import the neccessary libraries, we used graph4nlp library and adopted code from the text classification tutorial for our experiments\n",
        "### You can find details about this library here https://github.com/graph4ai/graph4nlp"
      ],
      "metadata": {
        "id": "-APK6zFLF6HH"
      },
      "id": "-APK6zFLF6HH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wsulzfQEyG0u",
        "outputId": "2f03427f-0623-4fb2-f8f4-25670fd7cb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchtext) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graph4nlp\n",
            "  Downloading graph4nlp-0.5.5-py2.py3-none-any.whl (32.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.2 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting ogb\n",
            "  Downloading ogb-1.3.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (4.64.0)\n",
            "Collecting pythonds\n",
            "  Downloading pythonds-1.2.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (1.0.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (2.6.3)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (3.7)\n",
            "Collecting dgl>=0.4\n",
            "  Downloading dgl-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 20.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (1.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from graph4nlp) (6.0)\n",
            "Collecting stanfordcorenlp\n",
            "  Downloading stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.4->graph4nlp) (1.21.6)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 87.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl>=0.4->graph4nlp) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4->graph4nlp) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4->graph4nlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4->graph4nlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl>=0.4->graph4nlp) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->graph4nlp) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp) (1.12.1+cu113)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp) (1.15.0)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp) (1.3.5)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb->graph4nlp) (4.1.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->graph4nlp) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->graph4nlp) (3.8.1)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=57262dd0bfea313ea49e794cfec91b8dc2f5ad3f8c2320140b83376312d53c46\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, tokenizers, psutil, outdated, huggingface-hub, transformers, stanfordcorenlp, pythonds, ogb, dgl, graph4nlp\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-0.9.0 graph4nlp-0.5.5 huggingface-hub-0.9.1 littleutils-0.2.2 ogb-1.3.4 outdated-0.2.1 psutil-5.9.1 pythonds-1.2.1 stanfordcorenlp-3.9.1.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graph4nlp-cu92\n",
            "  Downloading graph4nlp_cu92-0.5.5-py2.py3-none-any.whl (32.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (1.7.3)\n",
            "Collecting dgl-cu92>=0.4\n",
            "  Downloading dgl_cu92-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (35.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.8 MB 99.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (4.64.0)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (1.3.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (6.0)\n",
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (3.9.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (1.0.2)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (3.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (4.21.2)\n",
            "Requirement already satisfied: pythonds in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu92) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu92>=0.4->graph4nlp-cu92) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu92>=0.4->graph4nlp-cu92) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu92) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu92) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu92) (2022.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu92>=0.4->graph4nlp-cu92) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu92>=0.4->graph4nlp-cu92) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu92>=0.4->graph4nlp-cu92) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu92>=0.4->graph4nlp-cu92) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->graph4nlp-cu92) (3.1.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu92) (1.3.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu92) (1.15.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu92) (0.2.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu92) (1.12.1+cu113)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb->graph4nlp-cu92) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu92) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu92) (2022.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb->graph4nlp-cu92) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp->graph4nlp-cu92) (5.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu92) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu92) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu92) (0.9.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu92) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu92) (4.12.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->graph4nlp-cu92) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->graph4nlp-cu92) (3.8.1)\n",
            "Installing collected packages: dgl-cu92, graph4nlp-cu92\n",
            "Successfully installed dgl-cu92-0.6.1 graph4nlp-cu92-0.5.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graph4nlp-cu101\n",
            "  Downloading graph4nlp_cu101-0.5.5-py2.py3-none-any.whl (32.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (4.64.0)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (3.7)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (1.7.3)\n",
            "Collecting dgl-cu101>=0.4\n",
            "  Downloading dgl_cu101-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pythonds in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (1.2.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (2.6.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (4.21.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (1.0.2)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (1.3.4)\n",
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu101) (3.9.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101>=0.4->graph4nlp-cu101) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101>=0.4->graph4nlp-cu101) (2.23.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu101) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu101) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu101) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101>=0.4->graph4nlp-cu101) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101>=0.4->graph4nlp-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101>=0.4->graph4nlp-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101>=0.4->graph4nlp-cu101) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->graph4nlp-cu101) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu101) (1.15.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu101) (0.2.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu101) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu101) (1.12.1+cu113)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb->graph4nlp-cu101) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu101) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu101) (2022.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb->graph4nlp-cu101) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp->graph4nlp-cu101) (5.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu101) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu101) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu101) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu101) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu101) (0.12.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->graph4nlp-cu101) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->graph4nlp-cu101) (3.8.1)\n",
            "Installing collected packages: dgl-cu101, graph4nlp-cu101\n",
            "Successfully installed dgl-cu101-0.6.1 graph4nlp-cu101-0.5.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graph4nlp-cu102\n",
            "  Downloading graph4nlp_cu102-0.5.5-py2.py3-none-any.whl (32.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (3.7)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (1.0.2)\n",
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (3.9.1.1)\n",
            "Collecting dgl-cu102>=0.4\n",
            "  Downloading dgl_cu102-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (36.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (1.3.4)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (1.7.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (4.64.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (4.21.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (6.0)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (2.6.3)\n",
            "Requirement already satisfied: pythonds in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu102) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu102>=0.4->graph4nlp-cu102) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu102>=0.4->graph4nlp-cu102) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu102) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu102) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu102) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu102>=0.4->graph4nlp-cu102) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu102>=0.4->graph4nlp-cu102) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu102>=0.4->graph4nlp-cu102) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu102>=0.4->graph4nlp-cu102) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->graph4nlp-cu102) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu102) (1.12.1+cu113)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu102) (1.15.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu102) (0.2.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu102) (1.3.5)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb->graph4nlp-cu102) (0.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu102) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu102) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb->graph4nlp-cu102) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp->graph4nlp-cu102) (5.9.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu102) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu102) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu102) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu102) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu102) (0.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->graph4nlp-cu102) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->graph4nlp-cu102) (3.8.1)\n",
            "Installing collected packages: dgl-cu102, graph4nlp-cu102\n",
            "Successfully installed dgl-cu102-0.6.1 graph4nlp-cu102-0.5.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graph4nlp-cu110\n",
            "  Downloading graph4nlp_cu110-0.5.5-py2.py3-none-any.whl (32.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (2.6.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (4.21.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (4.64.0)\n",
            "Requirement already satisfied: nltk>=3.5 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (3.7)\n",
            "Requirement already satisfied: pythonds in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (6.0)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (1.3.4)\n",
            "Collecting dgl-cu110>=0.4\n",
            "  Downloading dgl_cu110-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (39.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 39.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (1.0.2)\n",
            "Requirement already satisfied: stanfordcorenlp in /usr/local/lib/python3.7/dist-packages (from graph4nlp-cu110) (3.9.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110>=0.4->graph4nlp-cu110) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110>=0.4->graph4nlp-cu110) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu110) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu110) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->graph4nlp-cu110) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110>=0.4->graph4nlp-cu110) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110>=0.4->graph4nlp-cu110) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110>=0.4->graph4nlp-cu110) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110>=0.4->graph4nlp-cu110) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->graph4nlp-cu110) (3.1.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu110) (0.2.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu110) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu110) (1.12.1+cu113)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb->graph4nlp-cu110) (1.15.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb->graph4nlp-cu110) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu110) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb->graph4nlp-cu110) (2022.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb->graph4nlp-cu110) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp->graph4nlp-cu110) (5.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu110) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu110) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu110) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu110) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers->graph4nlp-cu110) (0.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->graph4nlp-cu110) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->graph4nlp-cu110) (3.8.1)\n",
            "Installing collected packages: dgl-cu110, graph4nlp-cu110\n",
            "Successfully installed dgl-cu110-0.6.1 graph4nlp-cu110-0.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext # >=0.7.0\n",
        "!pip install graph4nlp\n",
        "!pip install graph4nlp-cu92\n",
        "!pip install graph4nlp-cu101\n",
        "!pip install graph4nlp-cu102\n",
        "!pip install graph4nlp-cu110"
      ],
      "id": "wsulzfQEyG0u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9b3c0d5"
      },
      "source": [
        "### Upload your test, train and developed dataset zipped in a folder <br>\n",
        "### The datasets for the papers were obtained from <a href=\"https://github.com/tanfiona/CausalNewsCorpus\">Link to datasets</a>"
      ],
      "id": "b9b3c0d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVRIWGx59srq",
        "outputId": "45d5ac7c-f46f-420d-a945-15afb72fea04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "   creating: data/data_submit/\n",
            "   creating: data/data_submit/trec/\n",
            "   creating: data/data_submit/trec/raw/\n",
            "  inflating: data/data_submit/trec/raw/test.txt  \n",
            "  inflating: data/data_submit/trec/raw/train.txt  \n",
            "  inflating: data/graphsage_undirected_node_emb.yaml  \n",
            "   creating: data/trec/\n",
            "   creating: data/trec/raw/\n",
            "  inflating: data/trec/raw/test.txt  \n",
            "  inflating: data/trec/raw/train.txt  \n",
            "  inflating: data/trec/raw/val.txt   \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/data.zip\""
      ],
      "id": "IVRIWGx59srq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd5f5762",
        "outputId": "9f4ce113-bbb5-4f6f-8fcb-86e421d3ed36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.multiprocessing\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import yaml\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from graph4nlp.pytorch.datasets.trec import TrecDataset\n",
        "from graph4nlp.pytorch.modules.evaluation.accuracy import Accuracy\n",
        "from graph4nlp.pytorch.modules.graph_construction import (\n",
        "    NodeEmbeddingBasedGraphConstruction,\n",
        "    NodeEmbeddingBasedRefinedGraphConstruction,\n",
        ")\n",
        "from graph4nlp.pytorch.modules.graph_embedding_initialization.embedding_construction import (\n",
        "    WordEmbedding,\n",
        ")\n",
        "from graph4nlp.pytorch.modules.graph_embedding_initialization.graph_embedding_initialization import (  # noqa\n",
        "    GraphEmbeddingInitialization,\n",
        ")\n",
        "from graph4nlp.pytorch.modules.graph_embedding_learning import GAT, GGNN, GraphSAGE\n",
        "from graph4nlp.pytorch.modules.loss.general_loss import GeneralLoss\n",
        "from graph4nlp.pytorch.modules.prediction.classification.graph_classification import FeedForwardNN\n",
        "from graph4nlp.pytorch.modules.utils import constants as Constants\n",
        "from graph4nlp.pytorch.modules.utils.generic_utils import EarlyStopping, grid, to_cuda\n",
        "from graph4nlp.pytorch.modules.utils.logger import Logger"
      ],
      "id": "cd5f5762"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "824bee58"
      },
      "source": [
        "### Build the text classifier"
      ],
      "id": "824bee58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "669b55bf"
      },
      "outputs": [],
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab, label_model, config):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.config = config\n",
        "        self.vocab_model = vocab\n",
        "        self.label_model = label_model\n",
        "        self.graph_name = self.config[\"graph_construction_args\"][\"graph_construction_share\"][\n",
        "            \"graph_name\"\n",
        "        ]\n",
        "        assert not (\n",
        "            self.graph_name in (\"node_emb\", \"node_emb_refined\") and config[\"gnn\"] == \"gat\"\n",
        "        ), \"dynamic graph construction does not support GAT\"\n",
        "\n",
        "        embedding_style = {\n",
        "            \"single_token_item\": True if self.graph_name != \"ie\" else False,\n",
        "            \"emb_strategy\": config.get(\"emb_strategy\", \"w2v_bilstm\"),\n",
        "            \"num_rnn_layers\": 1,\n",
        "            \"bert_model_name\": config.get(\"bert_model_name\", \"bert-base-uncased\"),\n",
        "            \"bert_lower_case\": True,\n",
        "        }\n",
        "\n",
        "        self.graph_initializer = GraphEmbeddingInitialization(\n",
        "            word_vocab=self.vocab_model.in_word_vocab,\n",
        "            embedding_style=embedding_style,\n",
        "            hidden_size=config[\"num_hidden\"],\n",
        "            word_dropout=config[\"word_dropout\"],\n",
        "            rnn_dropout=config[\"rnn_dropout\"],\n",
        "            fix_word_emb=not config[\"no_fix_word_emb\"],\n",
        "            fix_bert_emb=not config.get(\"no_fix_bert_emb\", False),\n",
        "        )\n",
        "\n",
        "        use_edge_weight = False\n",
        "        if self.graph_name == \"node_emb\":\n",
        "            self.graph_topology = NodeEmbeddingBasedGraphConstruction(\n",
        "                sim_metric_type=config[\"gl_metric_type\"],\n",
        "                num_heads=config[\"gl_num_heads\"],\n",
        "                top_k_neigh=config[\"gl_top_k\"],\n",
        "                epsilon_neigh=config[\"gl_epsilon\"],\n",
        "                smoothness_ratio=config[\"gl_smoothness_ratio\"],\n",
        "                connectivity_ratio=config[\"gl_connectivity_ratio\"],\n",
        "                sparsity_ratio=config[\"gl_sparsity_ratio\"],\n",
        "                input_size=config[\"num_hidden\"],\n",
        "                hidden_size=config[\"gl_num_hidden\"],\n",
        "            )\n",
        "            use_edge_weight = True\n",
        "        elif self.graph_name == \"node_emb_refined\":\n",
        "            self.graph_topology = NodeEmbeddingBasedRefinedGraphConstruction(\n",
        "                config[\"init_adj_alpha\"],\n",
        "                sim_metric_type=config[\"gl_metric_type\"],\n",
        "                num_heads=config[\"gl_num_heads\"],\n",
        "                top_k_neigh=config[\"gl_top_k\"],\n",
        "                epsilon_neigh=config[\"gl_epsilon\"],\n",
        "                smoothness_ratio=config[\"gl_smoothness_ratio\"],\n",
        "                connectivity_ratio=config[\"gl_connectivity_ratio\"],\n",
        "                sparsity_ratio=config[\"gl_sparsity_ratio\"],\n",
        "                input_size=config[\"num_hidden\"],\n",
        "                hidden_size=config[\"gl_num_hidden\"],\n",
        "            )\n",
        "            use_edge_weight = True\n",
        "\n",
        "        if \"w2v\" in self.graph_initializer.embedding_layer.word_emb_layers:\n",
        "            self.word_emb = self.graph_initializer.embedding_layer.word_emb_layers[\n",
        "                \"w2v\"\n",
        "            ].word_emb_layer\n",
        "        else:\n",
        "            self.word_emb = WordEmbedding(\n",
        "                self.vocab_model.in_word_vocab.embeddings.shape[0],\n",
        "                self.vocab_model.in_word_vocab.embeddings.shape[1],\n",
        "                pretrained_word_emb=self.vocab_model.in_word_vocab.embeddings,\n",
        "                fix_emb=not config[\"no_fix_word_emb\"],\n",
        "            ).word_emb_layer\n",
        "\n",
        "        if config[\"gnn\"] == \"gat\":\n",
        "            heads = [config[\"gat_num_heads\"]] * (config[\"gnn_num_layers\"] - 1) + [\n",
        "                config[\"gat_num_out_heads\"]\n",
        "            ]\n",
        "            self.gnn = GAT(\n",
        "                config[\"gnn_num_layers\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                heads,\n",
        "                direction_option=config[\"gnn_direction_option\"],\n",
        "                feat_drop=config[\"gnn_dropout\"],\n",
        "                attn_drop=config[\"gat_attn_dropout\"],\n",
        "                negative_slope=config[\"gat_negative_slope\"],\n",
        "                residual=config[\"gat_residual\"],\n",
        "                activation=F.elu,\n",
        "                allow_zero_in_degree=True,\n",
        "            )\n",
        "        elif config[\"gnn\"] == \"graphsage\":\n",
        "            self.gnn = GraphSAGE(\n",
        "                config[\"gnn_num_layers\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"graphsage_aggreagte_type\"],\n",
        "                direction_option=config[\"gnn_direction_option\"],\n",
        "                feat_drop=config[\"gnn_dropout\"],\n",
        "                bias=True,\n",
        "                norm=None,\n",
        "                activation=F.relu,\n",
        "                use_edge_weight=use_edge_weight,\n",
        "            )\n",
        "        elif config[\"gnn\"] == \"ggnn\":\n",
        "            self.gnn = GGNN(\n",
        "                config[\"gnn_num_layers\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                config[\"num_hidden\"],\n",
        "                feat_drop=config[\"gnn_dropout\"],\n",
        "                direction_option=config[\"gnn_direction_option\"],\n",
        "                bias=True,\n",
        "                use_edge_weight=use_edge_weight,\n",
        "            )\n",
        "        else:\n",
        "            raise RuntimeError(\"Unknown gnn type: {}\".format(config[\"gnn\"]))\n",
        "\n",
        "        self.clf = FeedForwardNN(\n",
        "            2 * config[\"num_hidden\"]\n",
        "            if config[\"gnn_direction_option\"] == \"bi_sep\"\n",
        "            else config[\"num_hidden\"],\n",
        "            config[\"num_classes\"],\n",
        "            [config[\"num_hidden\"]],\n",
        "            graph_pool_type=config[\"graph_pooling\"],\n",
        "            dim=config[\"num_hidden\"],\n",
        "            use_linear_proj=config[\"max_pool_linear_proj\"],\n",
        "        )\n",
        "\n",
        "        self.loss = GeneralLoss(\"CrossEntropy\")\n",
        "\n",
        "    def forward(self, graph_list, tgt=None, require_loss=True):\n",
        "        # graph embedding initialization\n",
        "        batch_gd = self.graph_initializer(graph_list)\n",
        "\n",
        "        # run dynamic graph construction if turned on\n",
        "        if hasattr(self, \"graph_topology\") and hasattr(self.graph_topology, \"dynamic_topology\"):\n",
        "            batch_gd = self.graph_topology.dynamic_topology(batch_gd)\n",
        "\n",
        "        # run GNN\n",
        "        self.gnn(batch_gd)\n",
        "\n",
        "        # run graph classifier\n",
        "        self.clf(batch_gd)\n",
        "        logits = batch_gd.graph_attributes[\"logits\"]\n",
        "\n",
        "        if require_loss:\n",
        "            loss = self.loss(logits, tgt)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "    def inference_forward(self, collate_data):\n",
        "        return self.forward(collate_data[\"graph_data\"], require_loss=False)\n",
        "\n",
        "    def post_process(self, logits, label_names):\n",
        "        logits_list = []\n",
        "\n",
        "        for idx in range(len(logits)):\n",
        "            logits_list.append(logits[idx].cpu().clone().numpy())\n",
        "\n",
        "        pred_tags = [label_names[pred.argmax()] for pred in logits_list]\n",
        "        return pred_tags\n",
        "\n",
        "    @classmethod\n",
        "    def load_checkpoint(cls, model_path):\n",
        "        \"\"\"The API to load the model.\n",
        "        Parameters\n",
        "        ----------\n",
        "        model_path : str\n",
        "            The saved model path.\n",
        "        Returns\n",
        "        -------\n",
        "        Class\n",
        "        \"\"\"\n",
        "        return torch.load(model_path)\n"
      ],
      "id": "669b55bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f4a64e2"
      },
      "source": [
        "### Build the model handler"
      ],
      "id": "8f4a64e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eda1f453"
      },
      "outputs": [],
      "source": [
        "class ModelHandler:\n",
        "    def __init__(self, config):\n",
        "        super(ModelHandler, self).__init__()\n",
        "        self.config = config\n",
        "        self.logger = Logger(\n",
        "            self.config[\"out_dir\"],\n",
        "            config={k: v for k, v in self.config.items() if k != \"device\"},\n",
        "            overwrite=True,\n",
        "        )\n",
        "        self.logger.write(self.config[\"out_dir\"])\n",
        "        self._build_dataloader()\n",
        "        self._build_model()\n",
        "        self._build_optimizer()\n",
        "        self._build_evaluation()\n",
        "\n",
        "    def _build_dataloader(self):\n",
        "        self.graph_name = self.config[\"graph_construction_args\"][\"graph_construction_share\"][\n",
        "            \"graph_name\"\n",
        "        ]\n",
        "        topology_subdir = \"{}_graph\".format(self.graph_name)\n",
        "        if self.graph_name == \"node_emb_refined\":\n",
        "            topology_subdir += \"_{}\".format(\n",
        "                self.config[\"graph_construction_args\"][\"graph_construction_private\"][\n",
        "                    \"dynamic_init_graph_name\"\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        dataset = TrecDataset(\n",
        "            root_dir=self.config[\"graph_construction_args\"][\"graph_construction_share\"][\"root_dir\"],\n",
        "            topology_subdir=topology_subdir,\n",
        "            graph_name=self.graph_name,\n",
        "            dynamic_init_graph_name=self.config[\"graph_construction_args\"][\n",
        "                \"graph_construction_private\"\n",
        "            ][\"dynamic_init_graph_name\"],\n",
        "            dynamic_init_topology_aux_args={\"dummy_param\": 0},\n",
        "            pretrained_word_emb_name=self.config[\"pretrained_word_emb_name\"],\n",
        "            merge_strategy=self.config[\"graph_construction_args\"][\"graph_construction_private\"][\n",
        "                \"merge_strategy\"\n",
        "            ],\n",
        "            edge_strategy=self.config[\"graph_construction_args\"][\"graph_construction_private\"][\n",
        "                \"edge_strategy\"\n",
        "            ],\n",
        "            min_word_vocab_freq=self.config.get(\"min_word_freq\", 1),\n",
        "            word_emb_size=self.config.get(\"word_emb_size\", 300),\n",
        "            seed=self.config[\"seed\"],\n",
        "            thread_number=self.config[\"graph_construction_args\"][\"graph_construction_share\"][\n",
        "                \"thread_number\"\n",
        "            ],\n",
        "            port=self.config[\"graph_construction_args\"][\"graph_construction_share\"][\"port\"],\n",
        "            timeout=self.config[\"graph_construction_args\"][\"graph_construction_share\"][\"timeout\"],\n",
        "            reused_label_model=None,\n",
        "        )\n",
        "\n",
        "        self.train_dataloader = DataLoader(\n",
        "            dataset.train,\n",
        "            batch_size=self.config[\"batch_size\"],\n",
        "            shuffle=True,\n",
        "            num_workers=self.config[\"num_workers\"],\n",
        "            collate_fn=dataset.collate_fn,\n",
        "        )\n",
        "        if not hasattr(dataset, \"val\"):\n",
        "            dataset.val = dataset.test\n",
        "        self.val_dataloader = DataLoader(\n",
        "            dataset.val,\n",
        "            batch_size=self.config[\"batch_size\"],\n",
        "            shuffle=False,\n",
        "            num_workers=self.config[\"num_workers\"],\n",
        "            collate_fn=dataset.collate_fn,\n",
        "        )\n",
        "        self.test_dataloader = DataLoader(\n",
        "            dataset.test,\n",
        "            batch_size=self.config[\"batch_size\"],\n",
        "            shuffle=False,\n",
        "            num_workers=self.config[\"num_workers\"],\n",
        "            collate_fn=dataset.collate_fn,\n",
        "        )\n",
        "        self.vocab_model = dataset.vocab_model\n",
        "        self.label_model = dataset.label_model\n",
        "        self.config[\"num_classes\"] = self.label_model.num_classes\n",
        "        self.num_train = len(dataset.train)\n",
        "        self.num_val = len(dataset.val)\n",
        "        self.num_test = len(dataset.test)\n",
        "        print(\n",
        "            \"Train size: {}, Val size: {}, Test size: {}\".format(\n",
        "                self.num_train, self.num_val, self.num_test\n",
        "            )\n",
        "        )\n",
        "        self.logger.write(\n",
        "            \"Train size: {}, Val size: {}, Test size: {}\".format(\n",
        "                self.num_train, self.num_val, self.num_test\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.model = TextClassifier(self.vocab_model, self.label_model, self.config).to(\n",
        "            self.config[\"device\"]\n",
        "        )\n",
        "\n",
        "    def _build_optimizer(self):\n",
        "        parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
        "        self.optimizer = optim.Adam(parameters, lr=self.config[\"lr\"])\n",
        "        self.stopper = EarlyStopping(\n",
        "            os.path.join(\n",
        "                self.config[\"out_dir\"],\n",
        "                self.config.get(\"model_ckpt_name\", Constants._SAVED_WEIGHTS_FILE),\n",
        "            ),\n",
        "            patience=self.config[\"patience\"],\n",
        "        )\n",
        "        self.scheduler = ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            mode=\"max\",\n",
        "            factor=self.config[\"lr_reduce_factor\"],\n",
        "            patience=self.config[\"lr_patience\"],\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "    def _build_evaluation(self):\n",
        "        self.metric = Accuracy([\"accuracy\"])\n",
        "\n",
        "    def train(self):\n",
        "        dur = []\n",
        "        for epoch in range(self.config[\"epochs\"]):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            train_acc = []\n",
        "            t0 = time.time()\n",
        "            for data in self.train_dataloader:\n",
        "                tgt = to_cuda(data[\"tgt_tensor\"], self.config[\"device\"])\n",
        "                data[\"graph_data\"] = data[\"graph_data\"].to(self.config[\"device\"])\n",
        "                logits, loss = self.model(data[\"graph_data\"], tgt, require_loss=True)\n",
        "\n",
        "                # add graph regularization loss if available\n",
        "                if data[\"graph_data\"].graph_attributes.get(\"graph_reg\", None) is not None:\n",
        "                    loss = loss + data[\"graph_data\"].graph_attributes[\"graph_reg\"]\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "                pred = torch.max(logits, dim=-1)[1].cpu()\n",
        "                train_acc.append(\n",
        "                    self.metric.calculate_scores(ground_truth=tgt.cpu(), predict=pred.cpu())[0]\n",
        "                )\n",
        "                dur.append(time.time() - t0)\n",
        "\n",
        "            val_acc = self.evaluate(self.val_dataloader)\n",
        "            self.scheduler.step(val_acc)\n",
        "            print(\n",
        "                \"Epoch: [{} / {}] | Time: {:.2f}s | Loss: {:.4f} |\"\n",
        "                \"Train Acc: {:.4f} | Val Acc: {:.4f}\".format(\n",
        "                    epoch + 1,\n",
        "                    self.config[\"epochs\"],\n",
        "                    np.mean(dur),\n",
        "                    np.mean(train_loss),\n",
        "                    np.mean(train_acc),\n",
        "                    val_acc,\n",
        "                )\n",
        "            )\n",
        "            self.logger.write(\n",
        "                \"Epoch: [{} / {}] | Time: {:.2f}s | Loss: {:.4f} |\"\n",
        "                \"Train Acc: {:.4f} | Val Acc: {:.4f}\".format(\n",
        "                    epoch + 1,\n",
        "                    self.config[\"epochs\"],\n",
        "                    np.mean(dur),\n",
        "                    np.mean(train_loss),\n",
        "                    np.mean(train_acc),\n",
        "                    val_acc,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if self.stopper.step(val_acc, self.model):\n",
        "                break\n",
        "\n",
        "        return self.stopper.best_score\n",
        "\n",
        "    def evaluate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_collect = []\n",
        "            gt_collect = []\n",
        "            for data in dataloader:\n",
        "                tgt = to_cuda(data[\"tgt_tensor\"], self.config[\"device\"])\n",
        "                data[\"graph_data\"] = data[\"graph_data\"].to(self.config[\"device\"])\n",
        "                logits = self.model(data[\"graph_data\"], require_loss=False)\n",
        "                pred_collect.append(logits)\n",
        "                gt_collect.append(tgt)\n",
        "\n",
        "            pred_collect = torch.max(torch.cat(pred_collect, 0), dim=-1)[1].cpu()\n",
        "            gt_collect = torch.cat(gt_collect, 0).cpu()\n",
        "            score = self.metric.calculate_scores(ground_truth=gt_collect, predict=pred_collect)[0]\n",
        "\n",
        "            return score\n",
        "\n",
        "    def predicted_values(self, dataloader):\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        pred_collect = []\n",
        "        gt_collect = []\n",
        "        for data in dataloader:\n",
        "          tgt = to_cuda(data[\"tgt_tensor\"], self.config[\"device\"])\n",
        "          data[\"graph_data\"] = data[\"graph_data\"].to(self.config[\"device\"])\n",
        "          logits = self.model(data[\"graph_data\"], require_loss=False)\n",
        "          pred_collect.append(logits)\n",
        "          gt_collect.append(tgt)\n",
        "\n",
        "        pred_collect = torch.max(torch.cat(pred_collect, 0), dim=-1)[1].cpu()\n",
        "        gt_collect = torch.cat(gt_collect, 0).cpu()\n",
        "        score = self.metric.calculate_scores(ground_truth=gt_collect, predict=pred_collect)[0]\n",
        "\n",
        "        return pred_collect\n",
        "\n",
        "    def test(self):\n",
        "        # restored best saved model\n",
        "        self.model = TextClassifier.load_checkpoint(self.stopper.save_model_path)\n",
        "\n",
        "        t0 = time.time()\n",
        "        acc = self.evaluate(self.test_dataloader)\n",
        "        dur = time.time() - t0\n",
        "        print(\n",
        "            \"Test examples: {} | Time: {:.2f}s |  Test Acc: {:.4f}\".format(self.num_test, dur, acc)\n",
        "        )\n",
        "        self.logger.write(\n",
        "            \"Test examples: {} | Time: {:.2f}s |  Test Acc: {:.4f}\".format(self.num_test, dur, acc)\n",
        "        )\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def test_preds(self):\n",
        "      self.model = TextClassifier.load_checkpoint(self.stopper.save_model_path)\n",
        "      preds = self.predicted_values(self.test_dataloader)\n",
        "      return preds"
      ],
      "id": "eda1f453"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWvS1OvnLwDj"
      },
      "outputs": [],
      "source": [
        "def main(config):\n",
        "    # configure\n",
        "    np.random.seed(config[\"seed\"])\n",
        "    torch.manual_seed(config[\"seed\"])\n",
        "\n",
        "    if not config[\"no_cuda\"] and torch.cuda.is_available():\n",
        "        print(\"[ Using CUDA ]\")\n",
        "        config[\"device\"] = torch.device(\"cuda\" if config[\"gpu\"] < 0 else \"cuda:%d\" % config[\"gpu\"])\n",
        "        torch.cuda.manual_seed(config[\"seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"seed\"])\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        cudnn.benchmark = False\n",
        "    else:\n",
        "        config[\"device\"] = torch.device(\"cpu\")\n",
        "\n",
        "    print(\"\\n\" + config[\"out_dir\"])\n",
        "\n",
        "    runner = ModelHandler(config)\n",
        "    t0 = time.time()\n",
        "\n",
        "    val_acc = runner.train()\n",
        "    test_acc = runner.test()\n",
        "\n",
        "    runtime = time.time() - t0\n",
        "    print(\"Total runtime: {:.2f}s\".format(runtime))\n",
        "    runner.logger.write(\"Total runtime: {:.2f}s\\n\".format(runtime))\n",
        "    runner.logger.close()\n",
        "\n",
        "    return val_acc, test_acc\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# ArgParse and Helper Functions #\n",
        "################################################################################\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"-config\", \"--config\", required=True, type=str, help=\"path to the config file\"\n",
        "    )\n",
        "    parser.add_argument(\"--grid_search\", action=\"store_true\", help=\"flag: grid search\")\n",
        "    args = vars(parser.parse_args())\n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "def get_config(config_path=\"config.yml\"):\n",
        "    with open(config_path, \"r\") as setting:\n",
        "        config = yaml.safe_load(setting)\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def print_config(config):\n",
        "    print(\"**************** MODEL CONFIGURATION ****************\")\n",
        "    for key in sorted(config.keys()):\n",
        "        val = config[key]\n",
        "        keystr = \"{}\".format(key) + (\" \" * (24 - len(key)))\n",
        "        print(\"{} -->   {}\".format(keystr, val))\n",
        "    print(\"**************** MODEL CONFIGURATION ****************\")\n",
        "\n",
        "\n",
        "def grid_search_main(config):\n",
        "    grid_search_hyperparams = []\n",
        "    log_path = config[\"out_dir\"]\n",
        "    for k, v in config.items():\n",
        "        if isinstance(v, list):\n",
        "            grid_search_hyperparams.append(k)\n",
        "            log_path += \"_{}_{}\".format(k, v)\n",
        "\n",
        "    logger = Logger(log_path, config=config, overwrite=True)\n",
        "\n",
        "    best_config = None\n",
        "    best_score = -1\n",
        "    configs = grid(config)\n",
        "    for cnf in configs:\n",
        "        for k in grid_search_hyperparams:\n",
        "            cnf[\"out_dir\"] += \"_{}_{}\".format(k, cnf[k])\n",
        "\n",
        "        val_score, test_score = main(cnf)\n",
        "        if best_score < test_score:\n",
        "            best_score = test_score\n",
        "            best_config = cnf\n",
        "            print(\"Found a better configuration: {}\".format(best_score))\n",
        "            logger.write(\"Found a better configuration: {}\".format(best_score))\n",
        "\n",
        "    print(\"\\nBest configuration:\")\n",
        "    logger.write(\"\\nBest configuration:\")\n",
        "    for k in grid_search_hyperparams:\n",
        "        print(\"{}: {}\".format(k, best_config[k]))\n",
        "        logger.write(\"{}: {}\".format(k, best_config[k]))\n",
        "\n",
        "    print(\"Best score: {}\".format(best_score))\n",
        "    logger.write(\"Best score: {}\\n\".format(best_score))\n",
        "    logger.close()"
      ],
      "id": "TWvS1OvnLwDj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ad3d820"
      },
      "source": [
        "### Set up the config"
      ],
      "id": "0ad3d820"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCj4urynUHG1"
      },
      "outputs": [],
      "source": [
        "def print_config(config):\n",
        "    print('**************** MODEL CONFIGURATION ****************')\n",
        "    for key in sorted(config.keys()):\n",
        "        val = config[key]\n",
        "        keystr = '{}'.format(key) + (' ' * (24 - len(key)))\n",
        "        print('{} -->   {}'.format(keystr, val))\n",
        "    print('**************** MODEL CONFIGURATION ****************')"
      ],
      "id": "GCj4urynUHG1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfNmHpWfUKTS",
        "outputId": "b03daa6e-c3f2-46ea-c83d-53dbac46729b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** MODEL CONFIGURATION ****************\n",
            "batch_size               -->   50\n",
            "dataset                  -->   trec\n",
            "emb_strategy             -->   w2v_bert_bilstm\n",
            "epochs                   -->   500\n",
            "gat_attn_dropout         -->   None\n",
            "gat_negative_slope       -->   None\n",
            "gat_num_heads            -->   None\n",
            "gat_num_out_heads        -->   None\n",
            "gat_residual             -->   False\n",
            "gl_connectivity_ratio    -->   None\n",
            "gl_epsilon               -->   0.5\n",
            "gl_metric_type           -->   weighted_cosine\n",
            "gl_num_heads             -->   1\n",
            "gl_num_hidden            -->   300\n",
            "gl_smoothness_ratio      -->   None\n",
            "gl_sparsity_ratio        -->   None\n",
            "gl_top_k                 -->   None\n",
            "gnn                      -->   graphsage\n",
            "gnn_direction_option     -->   undirected\n",
            "gnn_dropout              -->   0.3\n",
            "gnn_num_layers           -->   2\n",
            "gpu                      -->   0\n",
            "graph_construction_args  -->   {'graph_construction_share': {'graph_name': 'node_emb', 'root_dir': '/content/data/trec', 'thread_number': 10, 'port': 9000, 'timeout': 15000}, 'graph_construction_private': {'edge_strategy': 'homogeneous', 'merge_strategy': 'tailhead', 'sequential_link': True, 'as_node': False, 'dynamic_init_graph_name': None}}\n",
            "graph_pooling            -->   avg_pool\n",
            "graphsage_aggreagte_type -->   mean\n",
            "init_adj_alpha           -->   None\n",
            "lr                       -->   0.001\n",
            "lr_patience              -->   2\n",
            "lr_reduce_factor         -->   0.5\n",
            "max_pool_linear_proj     -->   False\n",
            "no_cuda                  -->   False\n",
            "no_fix_word_emb          -->   False\n",
            "num_hidden               -->   300\n",
            "num_workers              -->   8\n",
            "out_dir                  -->   out/trec/graphsage_undirected_node_emb_ckpt\n",
            "patience                 -->   5\n",
            "pretrained_word_emb_name -->   840B\n",
            "rnn_dropout              -->   0.1\n",
            "seed                     -->   1234\n",
            "val_split_ratio          -->   0.2\n",
            "word_dropout             -->   0.4\n",
            "**************** MODEL CONFIGURATION ****************\n"
          ]
        }
      ],
      "source": [
        "# config setup\n",
        "import platform, multiprocessing\n",
        "\n",
        "if platform.system() == \"Darwin\": # MacOS\n",
        "    multiprocessing.set_start_method('spawn')\n",
        "    \n",
        "config_file = '/content/data/graphsage_undirected_node_emb.yaml'\n",
        "config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
        "print_config(config)"
      ],
      "id": "IfNmHpWfUKTS"
    },
    {
      "cell_type": "code",
      "source": [
        "# run model\n",
        "np.random.seed(config['seed'])\n",
        "torch.manual_seed(config['seed'])\n",
        "\n",
        "if not config[\"no_cuda\"] and torch.cuda.is_available():\n",
        "    print(\"[ Using CUDA ]\")\n",
        "    config[\"device\"] = torch.device(\"cuda\" if config[\"gpu\"] < 0 else \"cuda:%d\" % config[\"gpu\"])\n",
        "    torch.cuda.manual_seed(config[\"seed\"])\n",
        "    torch.cuda.manual_seed_all(config[\"seed\"])\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    cudnn.benchmark = False\n",
        "else:\n",
        "    config[\"device\"] = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "ts = datetime.datetime.now().timestamp()\n",
        "config['out_dir'] += '_{}'.format(ts)\n",
        "print('\\n' + config['out_dir'])\n",
        "\n",
        "runner = ModelHandler(config)\n",
        "t0 = time.time()\n",
        "\n",
        "val_acc = runner.train()\n",
        "test_acc = runner.test()\n",
        "\n",
        "runtime = time.time() - t0\n",
        "print('Total runtime: {:.2f}s'.format(runtime))\n",
        "runner.logger.write('Total runtime: {:.2f}s\\n'.format(runtime))\n",
        "runner.logger.close()\n",
        "\n",
        "print('val acc: {}, test acc: {}'.format(val_acc, test_acc))"
      ],
      "metadata": {
        "id": "QvIfArPktGcV"
      },
      "id": "QvIfArPktGcV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}